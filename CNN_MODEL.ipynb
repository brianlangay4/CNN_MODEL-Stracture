{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952be497-2548-46b4-a033-5d87254d7ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the requred packages here\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import pickle\n",
    "import keras\n",
    "import tensorboard\n",
    "\n",
    "\n",
    "#we import rhe dataset into the project here\n",
    "DATDIR = \"Directory to your dataset\"\n",
    "#classifying the dataset put in separate classes \n",
    "Classes = [\"classfy the dataset\"] \n",
    "\n",
    "#loop in the dataset file to read the data\n",
    "for classes in Classes:\n",
    "    #path to classes of the dataset\n",
    "    path = os.path.join(DATDIR, classes)  \n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# sizing the data / scailing to afixed size\n",
    "#this wil save time from not re editting the data type of the dataset\n",
    "IMG_SIZE = #int value of the size of the dataset\n",
    "new_ImgArray = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "#now our dta is already prepared lets create the training data into the model\n",
    "training_data = []\n",
    "def create_training_data():\n",
    "    for classes in Classes:\n",
    "        path = os.path.join(DATDIR, classes)\n",
    "        #extracting number of sub folders that will be used as lables into our dataset\n",
    "        class_num = CATEGORIES.index(classes)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE)) \n",
    "                training_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            \n",
    "#returns the dataset to be trained for the model             \n",
    "create_training_data()\n",
    "\n",
    " \n",
    "#shuffling the data\n",
    "random.shuffle(training_data)\n",
    "\n",
    "#preparing X and y dataset for our model \n",
    "X = []\n",
    "y = []\n",
    "\n",
    "#give the image array values into X and y gets the lables as classes in 1,0 according to number of classes \n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "#shapping the data and save\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "y = np.array(y)\n",
    "pickle_out = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "#get the data\n",
    "X = pickle.load(open(\"X.pickle\",\"rb\"))\n",
    "y = pickle.load(open(\"y.pickle\",\"rb\"))\n",
    "\n",
    "#Normolizing the dataset\n",
    "X = X / 255.0\n",
    "\n",
    "#creating the model\n",
    "model = Sequential()\n",
    "\n",
    "#input layer\n",
    "model.add(Conv2D(64, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#repetition \n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#flatten \n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "#final layer\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "#configure the training of a model\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "#start training \n",
    "model.fit(X, y, batch_size=int, epochs=int)\n",
    "\n",
    "#saving the m odel \n",
    "model.save('Path')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
